/*******************************************************************************
* Copyright 2016 Intel Corporation
*
* Licensed under the Apache License, Version 2.0 (the "License");
* you may not use this file except in compliance with the License.
* You may obtain a copy of the License at
*
*     http://www.apache.org/licenses/LICENSE-2.0
*
* Unless required by applicable law or agreed to in writing, software
* distributed under the License is distributed on an "AS IS" BASIS,
* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
* See the License for the specific language governing permissions and
* limitations under the License.
*
* \file mkl_concat-inl.h
* \brief
* \author lingyan.guo@intel.com
*         zhenlin.luo@intel.com
*
*******************************************************************************/
#ifndef MXNET_OPERATOR_MKL_MKL_CONCAT_INL_H_
#define MXNET_OPERATOR_MKL_MKL_CONCAT_INL_H_
#include <dmlc/logging.h>
#include <dmlc/parameter.h>
#include <mxnet/operator.h>
#include <cstring>
#include <map>
#include <string>
#include <vector>
#include <utility>
#include "../operator_common.h"
#include "../channel_op_common.h"
#include "./mkl_util-inl.h"
namespace mxnet {
namespace op {


template<typename xpu, typename DType>
class MKLConcatOp : public Operator {
 public:
  static std::string getName() {
    return "MKLConcatOp";
  }
  explicit MKLConcatOp(
      const ConcatParam& param,
      const std::vector<TShape>& in_shapes,
      const std::vector<TShape>& out_shapes)
    : num_concats_(param.num_args), dimension_(param.dim) {
    fwd_top_data_ = MKLData<DType>::create();
    bwd_top_diff_ = MKLData<DType>::create();
    split_channels_.resize(num_concats_, 0);
    CHECK_EQ(in_shapes.size(), num_concats_);
    CHECK_EQ(out_shapes.size(), 1);
    LayerSetUp(in_shapes, out_shapes[0]);
  }
  virtual ~MKLConcatOp() {
    dnnDelete<DType>(concatFwd_);
    dnnDelete<DType>(concatBwd_);
  }

 private:
  // If shape has less than four dimensions, left pad one.
  // Else, flatten dimensions larger than the forth dimension.
  static inline TShape ConvertTo4DShape(const TShape& shape) {
    switch (shape.ndim()) {
    case 1:
      CHECK(false) << "Do not support 1-D concatenation.";
    case 2:
      return Shape4(shape[0], shape[1], 1, 1);
    case 3:
      return Shape4(shape[0], shape[1], shape[2], 1);
    default:
      return Shape4(shape[0], shape[1], shape[2], shape.ProdShape(3, shape.ndim()));
    }
  }
  void LayerSetUp(const std::vector<TShape>& in_shapes,
                  const TShape& out_shape) {
    const size_t dim_src = 4
    const size_t dim_dst = dim_src;
    size_t channels = 0;

    for (size_t i = 0; i < num_concats_; ++i) {
      padded_in_shapes_.push_back(ConvertTo4DShape(in_shapes[i]));
    }
    padded_out_shape_ = ConvertTo4DShape(out_shape);

    // Sanity check.
    CHECK_EQ(padded_in_shapes_.size(), num_concats_);
    for (size_t i = 1; i < num_concats_; ++i) {
      for (size_t j = 1; j < dim_src; ++j) {
        if (j == dimension_) continue;
        CHECK_EQ(padded_in_shapes_[0].shape_[j], padded_in_shapes_[i].shape_[j]);
      }
    }

    for (size_t i = 0; i < num_concats_; ++i) {
      const TShape& dshape = padded_in_shapes_[i];
      CHECK_EQ((int)dim_src, dshape.kDimension);

      fwd_bottom_data_.push_back(MKLData<DType>::create());
      bwd_bottom_diff_.push_back(MKLData<DType>::create());
      fwd_bottom_data_[i]->name = "fwd_bottom_data_[i]";
      bwd_bottom_diff_[i]->name = "bwd_bottom_data[i]";

      size_t *sizes_src = new size_t[dim_src];
      size_t *strides_src = new size_t[dim_src];
      for (size_t d = 0; d < dim_src; ++d) {
        sizes_src[d] = dshape[dim_src - d - 1];
        strides_src[d] = (d == 0) ? 1 : strides_src[d - 1] * sizes_src[d - 1];
      }

      split_channels_[i] = dshape[1];
      channels += split_channels_[i];
      fwd_bottom_data_[i]->create_user_layout(dim_src, sizes_src, strides_src);
      bwd_bottom_diff_[i]->create_user_layout(dim_src, sizes_src, strides_src);
      free(sizes_src);
      free(strides_src);
    }
    size_t *sizes_dst = new size_t[dim_dst];
    size_t *strides_dst = new size_t[dim_dst];
    for (size_t d = 0; d < dim_dst; ++d) {
      if (d == 2)
        sizes_dst[d] = channels;
      else
        sizes_dst[d] = padded_in_shapes_[0][dim_dst - 1 - d];
      strides_dst[d] = (d == 0) ? 1 : strides_dst[d - 1] * sizes_dst[d - 1];
    }
    bwd_top_diff_->create_user_layout(dim_dst, sizes_dst, strides_dst);
    fwd_top_data_->create_user_layout(dim_dst, sizes_dst, strides_dst);
    free(sizes_dst);
    free(strides_dst);

    concatFwd_ = NULL;
    concatBwd_ = NULL;

    // Create layouts.
    layouts_.resize(num_concats_);
    for (size_t n = 0; n < num_concats_; n++) {
    }
  }

 public:
  virtual void Forward(const OpContext &ctx,
                       const std::vector<TBlob> &in_data,
                       const std::vector<OpReqType> &req,
                       const std::vector<TBlob> &out_data,
                       const std::vector<TBlob> &aux_args) {
    using namespace mshadow;
    using namespace mshadow::expr;
    CHECK_EQ(static_cast<int>(in_data.size()), num_concats_);
    CHECK_EQ(out_data.size(), 1);
    CHECK_LT(dimension_, (size_t)in_data[concat_enum::kData0].ndim());
    Stream<xpu> *s = ctx.get_stream<xpu>();

    std::vector<Tensor<xpu, 4, DType> > data(num_concats_);
    for (size_t i = 0; i < num_concats_; ++i) {
      data[i] = mkl_experimental_direct_get_with_shape<xpu, 4, DType>(in_data[i], padded_in_shapes_[i], s);
    }
    Tensor<xpu, 4, DType> out = mkl_experimental_direct_get_with_shape<xpu, 4, DType>(
        out_data[0], padded_out_shape_, s);

#if MKL_EXPERIMENTAL == 1
    std::vector<void*> bottom_data;
#endif
    bool isFirstPass = (concatFwd_ == NULL);
    dnnLayout_t *layouts = NULL;
    bool *isBottomDataFilled = NULL;
    if (isFirstPass) {
      layouts = new dnnLayout_t[num_concats_];
      isBottomDataFilled = new bool[num_concats_]();
    }

    for (size_t n = 0; n < num_concats_; n++) {
#if MKL_EXPERIMENTAL == 1
      bottom_data.push_back(reinterpret_cast<void *>(mkl_prv_data<DType>(in_data[n])));
      if (bottom_data[n] == NULL) {
        bottom_data[n] =
          reinterpret_cast<void *>(const_cast<DType*>(data[n].dptr_));
#endif
        if (isFirstPass) {
          layouts[n] = fwd_bottom_data_[n]->layout_usr;
          isBottomDataFilled[n] = true;
        }
#if MKL_EXPERIMENTAL == 1
      } else if (isFirstPass) {
        std::shared_ptr<MKLMemHolder> bottom_data_mem = in_data[n].Mkl_mem_;
        std::shared_ptr<PrvMemDescr> bottom_prv_descriptor =
          bottom_data_mem->get_prv_descriptor();
        CHECK_EQ(bottom_prv_descriptor->get_descr_type(),
          PrvMemDescr::PRV_DESCR_MKL2017);
        std::shared_ptr<MKLData<DType> > mem_descr
          = std::static_pointer_cast<MKLData<DType>>
          (bottom_prv_descriptor);
        CHECK(mem_descr != NULL);
        fwd_bottom_data_[n] = mem_descr;
        layouts[n] = mem_descr->layout_int;
      }
#endif
    }

    if (isFirstPass) {
      MKLDNN_CALL(dnnConcatCreate<DType>(&concatFwd_, NULL, num_concats_, layouts));

      fwd_top_data_->create_internal_layout(concatFwd_, dnnResourceDst);
      bwd_top_diff_->create_internal_layout(concatFwd_, dnnResourceDst);

      MKLDNN_CALL(dnnSplitCreate<DType>(
            &concatBwd_, NULL, num_concats_,
            bwd_top_diff_->layout_int, split_channels_));

      for (size_t n = 0; n < num_concats_; ++n) {
        if (isBottomDataFilled[n]) continue;

        fwd_bottom_data_[n]->create_internal_layout(concatFwd_,
          (dnnResourceType_t)(dnnResourceMultipleSrc + n));
        bwd_bottom_diff_[n]->create_internal_layout(concatBwd_,
          (dnnResourceType_t)(dnnResourceMultipleDst + n));
      }
    }
    delete[] layouts;
    delete[] isBottomDataFilled;

    void *concat_res[dnnResourceNumber];
    for (size_t n = 0; n < num_concats_; ++n) {
#if MKL_EXPERIMENTAL == 1
    void * src_res = bottom_data[n];
#else
    void * src_res = data[n].dptr_;
#endif
      concat_res[dnnResourceMultipleSrc + n] = reinterpret_cast<void*>(src_res);
    }

#if MKL_EXPERIMENTAL == 1
    if (fwd_top_data_->conversion_needed()) {
      std::shared_ptr<MKLMemHolder> top_mem = out_data[concat_enum::kOut].Mkl_mem_;
        top_mem->set_prv_descriptor(fwd_top_data_);
      concat_res[dnnResourceDst] =
        reinterpret_cast<void*>(fwd_top_data_->prv_ptr());
    } else {
#endif
    concat_res[dnnResourceDst] =
      reinterpret_cast<void*>(out.dptr_);
#if MKL_EXPERIMENTAL == 1
    }
#endif

    MKLDNN_CALL(dnnExecute<DType>(concatFwd_, concat_res));
  }

  virtual void Backward(const OpContext &ctx,
                        const std::vector<TBlob> &out_grad,
                        const std::vector<TBlob> &in_data,
                        const std::vector<TBlob> &out_data,
                        const std::vector<OpReqType> &req,
                        const std::vector<TBlob> &in_grad,
                        const std::vector<TBlob> &aux_states) {
    using namespace mshadow;
    using namespace mshadow::expr;
    CHECK_EQ(out_grad.size(), 1);
    CHECK_EQ(in_grad.size(), static_cast<size_t>(num_concats_));
    Stream<xpu> *s = ctx.get_stream<xpu>();
    std::vector<Tensor<xpu, 4, DType> > grad_in(num_concats_);
    for (size_t i = 0; i < num_concats_; ++i) {
      grad_in[i] = mkl_experimental_direct_get_with_shape<xpu, 4, DType>(
          in_grad[i], padded_in_shapes_[i], s);
    }
    Tensor<xpu, 4, DType> grad = mkl_experimental_direct_get_with_shape<xpu, 4, DType>(
        out_grad[0], padded_out_shape_, s);

    int need_bwd = 0;
    for (size_t n = 0; n < num_concats_; n++) {
      need_bwd += req[n];
    }
    if (!need_bwd) {
      return;
    }

    void *concat_res[dnnResourceNumber];
    std::shared_ptr<MKLMemHolder> out_grad_mem =
#if MKL_EXPERIMENTAL == 1
      out_grad[concat_enum::kOut].Mkl_mem_;
#else
      NULL;
#endif
    concat_res[dnnResourceSrc] = bwd_top_diff_->get_converted_prv(grad.dptr_, true,
      out_grad_mem);

    for (size_t i = 0; i < num_concats_; ++i) {
#if MKL_EXPERIMENTAL == 1
      if (bwd_bottom_diff_[i]->conversion_needed()) {
        std::shared_ptr<MKLMemHolder> bottom_diff_mem = in_grad[i].Mkl_mem_;
        bottom_diff_mem->set_prv_descriptor(bwd_bottom_diff_[i]);
        concat_res[dnnResourceMultipleDst + i] = bwd_bottom_diff_[i]->prv_ptr();
      } else {
#endif
        concat_res[dnnResourceMultipleDst + i] = grad_in[i].dptr_;
#if MKL_EXPERIMENTAL == 1
      }
#endif
    }

    MKLDNN_CALL(dnnExecute<DType>(concatBwd_, concat_res));
  }

 private:
  const size_t num_concats_;
  const size_t dimension_;

  std::vector<size_t> split_channels_;
  std::vector<TShape> padded_in_shapes_;
  TShape padded_out_shape_;

  std::vector<dnnLayout_t> layouts_;
  dnnPrimitive_t concatFwd_{nullptr};
  dnnPrimitive_t concatBwd_{nullptr};

  std::shared_ptr<MKLData<DType> > fwd_top_data_;
  std::vector< std::shared_ptr<MKLData<DType> > > fwd_bottom_data_;
  std::shared_ptr<MKLData<DType> > bwd_top_diff_;
  std::vector< std::shared_ptr<MKLData<DType> > > bwd_bottom_diff_;

};  // class MKLConcatOp
}  // namespace op
}  // namespace mxnet

#endif  // MXNET_OPERATOR_MKL_MKL_CONCAT_INL_H_
